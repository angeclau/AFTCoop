% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/proxGD.coop.R
\name{proxGD.coop}
\alias{proxGD.coop}
\title{Proximal Gradient Descent for Cooperative AFT Model Estimation}
\usage{
proxGD.coop(
  X,
  Y,
  delta,
  coop,
  beta0,
  sigma = NULL,
  rho = NULL,
  lambda = NULL,
  model,
  niter = 1000
)
}
\arguments{
\item{X}{Matrix of standardized covariates}

\item{Y}{Vector of log observed survival times or log censored times (response variable in log scale)}

\item{delta}{Vector of censoring indicators (1 for event, 0 for censored)}

\item{coop}{Cooperative matrix (typically t(Xtilde) \%*\% Xtilde)}

\item{beta0}{Initial vector of coefficients}

\item{sigma}{Scale parameter for the AFT model}

\item{rho}{Cooperation parameter controlling L1 vs cooperative trade-off (}

\item{lambda}{Regularization parameter}

\item{model}{Character string specifying the AFT model type}

\item{niter}{Maximum number of iterations (default: 1000)}
}
\value{
A list containing:
\itemize{
\item beta: Vector of optimized coefficients
\item objective: Final value of the objective function
}
}
\description{
proxGD.coop implements proximal gradient descent optimization for cooperative estimation in
Accelerated Failure Time (AFT) models. The function minimizes an objective function
that combines negative log-likelihood, L1 regularization, and a cooperative term.
}
\details{
The function minimizes the objective:
\deqn{f(\beta) = -\log L(\beta) + \lambda\rho\|\beta\|_1 + \lambda(1-\rho)\beta^T C\beta}
where:
\itemize{
\item \eqn{-\log L(\beta)} is the negative log-likelihood
\item \eqn{\|\beta\|_1} is the L1 norm (lasso penalty)
\item \eqn{\beta^T C\beta} is the cooperative term
}

The algorithm uses:
\itemize{
\item Adaptive line search with backtracking
\item Lipschitz constant adaptation
\item Early stopping based on relative change in objective
\item Memory-efficient vector operations
}

Convergence is determined by relative change in objective value falling below
\code{conv = 0.001}.
}
\note{
Last change 07/04/2025
}
\section{Implementation Notes}{

\itemize{
\item Uses pre-allocation for memory efficiency
\item Implements line search with sufficient decrease condition
\item Precomputes lambda terms to avoid repeated multiplication
\item Uses vectorized operations where possible
}
}

\seealso{
\code{\link{prox.l1}} for the proximal operator of L1 norm
\code{\link{nll}} for negative log-likelihood computation
\code{\link{gradient}} for gradient computation
\code{\link{hessian_coop}} for Hessian and Lipschitz constant computation
}
\keyword{internal}
